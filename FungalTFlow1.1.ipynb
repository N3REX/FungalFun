{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungal Fun\n",
    "ML approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports/seeds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "\n",
    "    feature_columns = [\n",
    "        'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color', \n",
    "        'does-bruise-or-bleed', \n",
    "        'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "        'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color', \n",
    "        'veil-type', 'veil-color', 'has-ring', 'ring-type', \n",
    "        'spore-print-color',\n",
    "        'habitat', 'season'\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Remove columns with high percentage of null values (>40%)\n",
    "    null_percentages = df.isnull().mean()\n",
    "    columns_to_drop = null_percentages[null_percentages > 0.4].index.tolist()\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Drop any remaining rows with NA values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df[feature_columns]\n",
    "    y = df['class']  # Assuming 'class' is the column indicating edible/poisonous\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for column in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column].astype(str))\n",
    "    \n",
    "    # Encode target variable\n",
    "    le_y = LabelEncoder()\n",
    "    y = le_y.fit_transform(y)\n",
    "    \n",
    "    return X, y, le_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved\n",
    "def load_and_preprocess_data(filepath):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Print out all column names for diagnostic purposes\n",
    "    print(\"Available columns in the dataset:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Identify columns to drop based on null percentage\n",
    "    null_percentages = df.isnull().mean()\n",
    "    columns_to_drop = null_percentages[null_percentages > 0.4].index.tolist()\n",
    "    print(\"\\nColumns to be dropped due to high null percentage:\")\n",
    "    print(columns_to_drop)\n",
    "    \n",
    "    # Drop columns with high null percentage\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Drop any remaining rows with NA values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Identify the actual feature columns (excluding the target)\n",
    "    feature_columns = [col for col in df.columns if col != 'class']\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df[feature_columns]\n",
    "    y = df['class']\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for column in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column].astype(str))\n",
    "    \n",
    "    # Encode target variable\n",
    "    le_y = LabelEncoder()\n",
    "    y = le_y.fit_transform(y)\n",
    "    \n",
    "    # Print some additional diagnostic information\n",
    "    print(f\"\\nFeature columns used: {feature_columns}\")\n",
    "    print(f\"Number of features: {len(feature_columns)}\")\n",
    "    print(f\"Number of samples: {len(X)}\")\n",
    "    \n",
    "    return X, y, le_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 56\n"
     ]
    }
   ],
   "source": [
    "def create_neural_network(input_shape):\n",
    "    model = Sequential([\n",
    "        # Input layer with BatchNormalization\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Hidden layers with different configurations\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset:\n",
      "['id', 'class', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n",
      "\n",
      "Columns to be dropped due to high null percentage:\n",
      "['gill-spacing', 'stem-root', 'stem-surface', 'veil-type', 'veil-color', 'spore-print-color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n",
      "/var/folders/wz/l950mtnn11sgl5gd1ffmqgvm0000gn/T/ipykernel_50889/1234075675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = le.fit_transform(X[column].astype(str))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature columns used: ['id', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-color', 'stem-height', 'stem-width', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season']\n",
      "Number of features: 15\n",
      "Number of samples: 1930108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38603/38603 [==============================] - 28s 707us/step - loss: 0.2650 - accuracy: 0.8959 - val_loss: 0.1078 - val_accuracy: 0.9674\n",
      "Epoch 2/5\n",
      "38603/38603 [==============================] - 28s 717us/step - loss: 0.1945 - accuracy: 0.9337 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
      "Epoch 3/5\n",
      "38603/38603 [==============================] - 28s 736us/step - loss: 0.1837 - accuracy: 0.9384 - val_loss: 0.0958 - val_accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "38603/38603 [==============================] - 28s 714us/step - loss: 0.1777 - accuracy: 0.9412 - val_loss: 0.0922 - val_accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "38603/38603 [==============================] - 27s 707us/step - loss: 0.1736 - accuracy: 0.9430 - val_loss: 0.0907 - val_accuracy: 0.9733\n",
      "\n",
      "Test Accuracy: 0.9731\n",
      "12064/12064 [==============================] - 4s 308us/step\n",
      "12064/12064 [==============================] - 4s 331us/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97    179132\n",
      "           1       0.98      0.97      0.97    206890\n",
      "\n",
      "    accuracy                           0.97    386022\n",
      "   macro avg       0.97      0.97      0.97    386022\n",
      "weighted avg       0.97      0.97      0.97    386022\n",
      "\n",
      "Visualizations have been saved:\n",
      "1. training_history.png\n",
      "2. confusion_matrix.png\n",
      "3. roc_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bcmain/miniconda3/envs/pandas_practice/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y, label_encoder = load_and_preprocess_data('/Users/bcmain/Desktop/poisonous_mushrooms.csv')\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_neural_network(X_train.shape[1])\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "    y_scores = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Detailed Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualizations\n",
    "    plot_training_history(history)\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    plot_roc_curve(y_test, y_scores)\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('mushroom_classifier.h5')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history = main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
